{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RabindraAI",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvvXHUuqYaXmwuO0ELSMpT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhanShaheb34/RabindraAI/blob/main/RabindraAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x2HMQQVuywQ"
      },
      "source": [
        "# RabindraAI\n",
        "\n",
        "A text generator trained on poems of Rabindranath Tagore\n",
        "\n",
        "Dataset taken from [Kaggle - Rabindranath Tagore Online Variorum](https://www.kaggle.com/nrkapri/rabindranath-tagore-online-variorum)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNDAQoNNOfgc"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g6IG8RQvjb5"
      },
      "source": [
        "## Reading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CpZpbzTOpkR"
      },
      "source": [
        "text = open('poems.txt').read()[:500000]\n",
        "chars = list(set(text))\n",
        "data_size, vocab_size = len(text), len(chars)\n",
        "char_indices = { ch:i for i,ch in enumerate(chars) }\n",
        "indices_char = { i:ch for i,ch in enumerate(chars) }"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxpPvimHvsvA"
      },
      "source": [
        "## Preparing the dataset\n",
        "\n",
        "Here we will be giving 40 characters as input to our model and try to guess the next character.\n",
        "\n",
        "So we are createing two variable `x` and `y` to save the input and output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV79dAPMO4Gc",
        "outputId": "70b68c15-b872-4b40-cd87-21338e208b93"
      },
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print(\"Number of sequences:\", len(sentences))\n",
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)))\n",
        "y = np.zeros((len(sentences), len(chars)))\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 166654\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4JDaNz_wQkz"
      },
      "source": [
        "## Model\n",
        "\n",
        "We will use a two layer LSTM for this task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNX64h_xO6zJ"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.InputLayer(input_shape=(maxlen, len(chars))),\n",
        "        layers.LSTM(128, return_sequences=True),\n",
        "        layers.LSTM(128),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(len(chars), activation=\"softmax\")\n",
        "    ]\n",
        ")\n",
        "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY87T3lfw4IU",
        "outputId": "ee4e2b27-d6b0-439d-e153-f1e4e219a2cc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 40, 128)           120832    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 107)               13803     \n",
            "=================================================================\n",
            "Total params: 266,219\n",
            "Trainable params: 266,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sld5pFqmwbV4"
      },
      "source": [
        "## Sample Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlqsVRB-O9U7"
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k55YXSYweTA"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4xZVi1DPBUs"
      },
      "source": [
        "epochs = 40\n",
        "batch_size = 128\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.fit(x, y, batch_size=batch_size, epochs=1)\n",
        "    print()\n",
        "    print(\"==> Generating text after epoch: %d\" % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0]:\n",
        "        print(\"==> Diversity:\", diversity)\n",
        "\n",
        "        generated = \"\"\n",
        "        sentence = text[start_index : start_index + maxlen]\n",
        "        print('==> Generating with seed:\\n' + sentence)\n",
        "        in_sentence = sentence\n",
        "\n",
        "        for i in range(300):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.0\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "            sentence = sentence[1:] + next_char\n",
        "            generated += next_char\n",
        "\n",
        "        print(\"==> Generated: \\n\", in_sentence + generated)\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZr7mrK3wiN-"
      },
      "source": [
        "## Testing the Model\n",
        "\n",
        "We can give our model a sentence of atmost 40 characters as input. And it will generate a poem based on the input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj_QSLxarE34",
        "outputId": "359e401a-6729-484c-83d6-c7e38588943b"
      },
      "source": [
        "generated = \"\"\n",
        "diversity = 0.5\n",
        "sentence = \"দেখেছি তোমার ওই দু চো\"\n",
        "if len(sentence) > maxlen:\n",
        "  sentence = sentence[:maxlen]\n",
        "else:\n",
        "  pad = \" \" * (maxlen - len(sentence))\n",
        "  sentence = pad + sentence\n",
        "print('==> Generating with seed:\\n' + sentence)\n",
        "in_sentence = sentence\n",
        "\n",
        "for i in range(400):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_indices[char]] = 1.0\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = sample(preds, diversity)\n",
        "    next_char = indices_char[next_index]\n",
        "    sentence = sentence[1:] + next_char\n",
        "    generated += next_char\n",
        "\n",
        "print(\"==> Generated: \\n\", in_sentence + generated)\n",
        "print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Generating with seed:\n",
            "                   দেখেছি তোমার ওই দু চো\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==>Generated: \n",
            "                    দেখেছি তোমার ওই দু চোখে,\n",
            "মানা মনে বাঁধি মনে যে সে কানে বেঁশি।\n",
            "কোনো বাঁধি সে কে দেখে দিল মনে,\n",
            "বাঁধা বিদ্রোহ বালান\n",
            "নিত্য আঁখি হতে আকাশ সে বিচ্ছুক্ত প্রদ্য\n",
            "বিজন বালুকায়ে\n",
            "সহসা মিলি দিবে সাথ।\n",
            "বিরহ বিস্তানিতেছিলে তারে আমার ভাঙিয়া।\n",
            "সেই মনো বুঝি বাঁধনে যে বাণী\n",
            "বসন্ত কুজ নশীর্য বুলায়।\n",
            "দিনে নিদ্রায় আসি\n",
            "কাঁপা দিয়ে উঠে বাঁধয়ি\n",
            "কিন্দে তার স্বর্গ তার\n",
            "সেই তো না কোহার\n",
            "তারে যায় বাজে মনে\n",
            "বিদায়ের বাঁধন তবে\n",
            "আকাশে তার করি তারা\n",
            "মেলে দিয়ে আম\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEkMcHOyw0JW"
      },
      "source": [
        "## Further Reading\n",
        "\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)"
      ]
    }
  ]
}